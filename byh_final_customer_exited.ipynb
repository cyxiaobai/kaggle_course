{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入所需要的包\n",
    "#### 就是导入机器学习所需要得包，可以使用pip或者conda命令来安装这些包，但是建议使用同一个，要么一直用pip，要么一直用conda。并且在安装之前可以先询问一下AI所需要安装的版本，不然可能到时候因为版本不兼容而报错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import axes\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据读取\n",
    "#### 读取一下数据，数据集分为训练集和测试集。训练集呢是拿来让模型学习的，让模型拿来确定各种参数。测试集呢就是拿来验证这个模型的效果。\n",
    "#### 我觉得要进行机械学习一开始最重要的就是要了解你的数据集，要知道你的数据集包含哪些特征，还要知道特征的形式，这些都是很重要的，非常忌讳不看数据就直接在那里开始着手训练，这样也是云里雾里的。本次获得的一些是关于银行的数据，这是一个关于预测用户去留的问题，0表示的就是存留，1表示的就是客户流失。其实我觉得了解一些这些背景也是很重要的，这样你就大概可以初步的知道哪些特征重要，哪些特征不重要，可以对特征进行初步的筛选。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集形状 (Rows, Cols): (15000, 14)\n",
      "\n",
      "训练集前 5 行：\n",
      "   id  CustomerId       Surname  CreditScore Geography  Gender   Age  Tenure  \\\n",
      "0   0  15709511.0        Ch'ang        754.0     Spain    Male  40.0     8.0   \n",
      "1   1  15592761.0      Genovese        579.0    France  Female  28.0     1.0   \n",
      "2   2  15579914.0           Yeh        744.0    France  Female  56.0     5.0   \n",
      "3   3  15669611.0  Nwachinemelu        697.0    France    Male  29.0     2.0   \n",
      "4   4  15761775.0         Hs?eh        628.0    France  Female  22.0     9.0   \n",
      "\n",
      "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
      "0  102954.68            2.0        1.0             1.0        149238.35   \n",
      "1       0.00            2.0        1.0             0.0         64869.32   \n",
      "2       0.00            1.0        1.0             0.0        158816.03   \n",
      "3       0.00            2.0        1.0             0.0         55775.72   \n",
      "4       0.00            2.0        1.0             0.0         49653.39   \n",
      "\n",
      "   Exited  \n",
      "0     0.0  \n",
      "1     0.0  \n",
      "2     1.0  \n",
      "3     0.0  \n",
      "4     0.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15000 entries, 0 to 14999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   id               15000 non-null  int64  \n",
      " 1   CustomerId       15000 non-null  float64\n",
      " 2   Surname          15000 non-null  object \n",
      " 3   CreditScore      15000 non-null  float64\n",
      " 4   Geography        15000 non-null  object \n",
      " 5   Gender           15000 non-null  object \n",
      " 6   Age              15000 non-null  float64\n",
      " 7   Tenure           15000 non-null  float64\n",
      " 8   Balance          15000 non-null  float64\n",
      " 9   NumOfProducts    15000 non-null  float64\n",
      " 10  HasCrCard        15000 non-null  float64\n",
      " 11  IsActiveMember   15000 non-null  float64\n",
      " 12  EstimatedSalary  15000 non-null  float64\n",
      " 13  Exited           15000 non-null  float64\n",
      "dtypes: float64(10), int64(1), object(3)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df=pd.read_csv(\"./data/train.csv\")\n",
    "test_df=pd.read_csv(\"./data/test.csv\")\n",
    "# 2. 看看数据的样子\n",
    "print(\"训练集形状 (Rows, Cols):\", train_df.shape)\n",
    "print(\"\\n训练集前 5 行：\")\n",
    "print(train_df.head()) \n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据清理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据清理是一个很重要的步骤，数据的好坏直接的决定了你的模型的上限。\n",
    "#### 主要就包括缺失值的处理，异常值的处理。如果是缺失值我们可以尝试使用众数或者平均数来填充，当然这取决于具体的特征。如果是异常值的话我们就需要修改这些异常值，不然这些异常就会作为噪声对我们的模型学习产生巨大的影响。\n",
    "#### 本次训练只检查了缺失值，并没有检查异常值，并且缺失值的个数为0。因为这个数据集是为新手准备的练手数据集，所以很简单。但是实际上需要处理的数据集都是很麻烦的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集缺失值统计：\n",
      "id                 0\n",
      "CustomerId         0\n",
      "Surname            0\n",
      "CreditScore        0\n",
      "Geography          0\n",
      "Gender             0\n",
      "Age                0\n",
      "Tenure             0\n",
      "Balance            0\n",
      "NumOfProducts      0\n",
      "HasCrCard          0\n",
      "IsActiveMember     0\n",
      "EstimatedSalary    0\n",
      "Exited             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 检查缺失值 ---\n",
    "print(\"训练集缺失值统计：\")\n",
    "print(train_df.isnull().sum())\n",
    "# --- 2. 缺失值填充策略 ---\n",
    "# 对于数值型变量（年龄、薪水等），如果缺失，用“中位数”填充是最稳妥的（防止被极值拉偏）\n",
    "# 对于分类变量（地理位置等），如果有缺失，可以用“众数”填充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征工程就是对这些特征进行一系列的处理，包括添加新特征，特征编码等步骤，接下来我做的就是进行新特征的添加。\n",
    "#### 为什么要进行特征工程呢？目的就是为了使我们的模型预测效果更好，如果我们在老特征上面进行衍生添加了新特征，这个新特征对我们的模型预测室友效果的，那说明这个特征工程还是做得有意义的。\n",
    "#### 这一部分是通过已有特征来进行计算得到的新特征。一个是账户余额/薪资，一个是忠诚度/年龄比，这是个人感觉可能这两个新特征会对客户去留产生影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#账户余额/薪资\n",
    "#比值越高说明更倾向于存钱\n",
    "train_df['BalanceSalaryRatio'] = train_df['Balance'] / (train_df['EstimatedSalary'] + 1e-5)\n",
    "test_df['BalanceSalaryRatio'] = test_df['Balance'] / (test_df['EstimatedSalary'] + 1e-5)\n",
    "\n",
    "# 2. 忠诚度/年龄比 (Tenure / Age)\n",
    "# 逻辑：同样的 5 年老客户，20岁的人（占了他1/4的人生）比 50岁的人（只占1/10）对银行的情感依赖可能更重。\n",
    "train_df['TenureByAge'] = train_df['Tenure'] / (train_df['Age'] + 1e-5)\n",
    "test_df['TenureByAge'] = test_df['Tenure'] / (test_df['Age'] + 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 接下来是进行了一个特征重要性的判断，就是看哪些特征跟y值（用户去留）相关。负值呢代表是对客户留存起到了积极的作用，正值则是导致客户流失的原因，可以看到年龄是对这个y值影响最大的，我们创造的一个特征忠诚度/年龄比(Tenure / Age)对这个也有不小的影响（因为公式中有年龄，受了年龄不小的影响）。但是另外一个创造的新特征账户余额/薪资（BalanceSalaryRatio）确影响很小。一个好的特征工程可以直接影响最后模型的效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TenureByAge          -0.162805\n",
      "CreditScore          -0.045404\n",
      "Tenure               -0.015022\n",
      "BalanceSalaryRatio   -0.002198\n",
      "EstimatedSalary       0.023511\n",
      "Balance               0.155268\n",
      "Age                   0.481368\n",
      "Name: Exited, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "numeric_cols = ['Age', 'CreditScore', 'Balance', 'EstimatedSalary', 'Tenure', \n",
    "                'BalanceSalaryRatio', 'TenureByAge']\n",
    "correlations = train_df[numeric_cols + ['Exited']].corr()['Exited'].drop('Exited').sort_values()\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 特征编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这里主要是关于特征编码的部分。为什么要进行特征编码呢？是因为机器学习究其本质也是数学的运算，所以有些字符特征不能直接给模型，要先把他量化过后再给模型。我们这里组要介绍两种方法，独热编码和标签编码。\n",
    "#### 标签编码接把文字映射成整数，但是这种方法会让模型认为数值大的一个类别较大，影响模型判断。\n",
    "#### 在许多特征当中，就比如这次需要编码的特征，一个是地区，一个是性别，类别之间没有大小关系，且类别数量不多。这个就适合独热编码。这样他就不会因为数值的大小而认为编码的特征也有大小。\n",
    "#### 当然这里我们还对特征进行筛选，就像我们前面提到的那样，对背景有一定了解，比如我们知道用户ID和名字这一类的特征对用户去留并没有影响，所以我们就可以直接把他们筛掉，这些对我们模型训练没有一点用处，当然，对于哪些对y值不重要的特征我也一样筛除掉了。\n",
    "#### 在这里我也对训练集和验证集进行了划分按照8：2的方法进行划分（其实可以使用k-fold这种方法更加的先进）。划分训练集和验证集的核心目的是为了防止过拟合并评估模型的泛化能力；训练集用于让模型拟合参数、学习数据的内在规律（即“学习”），而验证集则作为模型从未见过的独立样本（即“模拟考”），用于实时监控模型对未知数据的预测水平，从而指导超参数调整并触发早停机制（Early Stopping），确保模型不仅能“记住”旧数据，更能“读懂”新数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>BalanceSalaryRatio</th>\n",
       "      <th>TenureByAge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15709511.0</td>\n",
       "      <td>Ch'ang</td>\n",
       "      <td>754.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>102954.68</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149238.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689867</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15592761.0</td>\n",
       "      <td>Genovese</td>\n",
       "      <td>579.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64869.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15579914.0</td>\n",
       "      <td>Yeh</td>\n",
       "      <td>744.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>158816.03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15669611.0</td>\n",
       "      <td>Nwachinemelu</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55775.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15761775.0</td>\n",
       "      <td>Hs?eh</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49653.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.409091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  CustomerId       Surname  CreditScore  Geography  Gender   Age  Tenure  \\\n",
       "0   0  15709511.0        Ch'ang        754.0          2       1  40.0     8.0   \n",
       "1   1  15592761.0      Genovese        579.0          0       0  28.0     1.0   \n",
       "2   2  15579914.0           Yeh        744.0          0       0  56.0     5.0   \n",
       "3   3  15669611.0  Nwachinemelu        697.0          0       1  29.0     2.0   \n",
       "4   4  15761775.0         Hs?eh        628.0          0       0  22.0     9.0   \n",
       "\n",
       "     Balance  NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0  102954.68            2.0        1.0             1.0        149238.35   \n",
       "1       0.00            2.0        1.0             0.0         64869.32   \n",
       "2       0.00            1.0        1.0             0.0        158816.03   \n",
       "3       0.00            2.0        1.0             0.0         55775.72   \n",
       "4       0.00            2.0        1.0             0.0         49653.39   \n",
       "\n",
       "   Exited  BalanceSalaryRatio  TenureByAge  \n",
       "0     0.0            0.689867     0.200000  \n",
       "1     0.0            0.000000     0.035714  \n",
       "2     1.0            0.000000     0.089286  \n",
       "3     0.0            0.000000     0.068965  \n",
       "4     0.0            0.000000     0.409091  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore  Geography  Gender   Age    Balance  NumOfProducts  \\\n",
      "9451        567.0          0       1  43.0       0.00            1.0   \n",
      "2071        612.0          1       1  35.0  104498.79            1.0   \n",
      "77          619.0          0       1  34.0       0.00            2.0   \n",
      "5464        710.0          0       0  43.0       0.00            2.0   \n",
      "8844        662.0          1       1  40.0  120165.40            1.0   \n",
      "\n",
      "      HasCrCard  IsActiveMember  EstimatedSalary  TenureByAge  \n",
      "9451        1.0             0.0         71843.95     0.186046  \n",
      "2071        1.0             0.0         51112.80     0.114286  \n",
      "77          1.0             1.0        141152.28     0.058824  \n",
      "5464        1.0             1.0        175072.47     0.046512  \n",
      "8844        1.0             1.0         72993.65     0.050000  \n",
      "数据准备完毕！\n",
      "训练集形状: (12000, 10)\n",
      "验证集形状: (3000, 10)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "categorical_cols = [\"Gender\", \"Geography\"]\n",
    "\n",
    "for feature in categorical_cols:\n",
    "    train_df[feature] = encoder.fit_transform(train_df[feature])\n",
    "    test_df[feature] = encoder.transform(test_df[feature])\n",
    "display(train_df.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "drop_cols = ['id', 'CustomerId', 'Surname', 'Exited','Tenure','BalanceSalaryRatio']\n",
    "X = train_df.drop(columns=drop_cols)\n",
    "y = train_df['Exited']\n",
    "X_test_final = test_df.drop(columns=['id', 'CustomerId', 'Surname','Tenure','BalanceSalaryRatio'])\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test_final)\n",
    "print(X_train.head())\n",
    "\n",
    "print(\"数据准备完毕！\")\n",
    "print(f\"训练集形状: {X_train_scaled.shape}\")\n",
    "print(f\"验证集形状: {X_val_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据已经准好了，接下来就是对模型进行训练了，让模型来学习数据之中的规律了。\n",
    "#### 这里我们使用了三个模型来进行训练，模型里面有许多参数要进行合理的设置，比如说什么学习率啊，什么树的最大深度这些都是要进行调整的，可以根据每次训练的结果来进行参数的调节。\n",
    "#### 这里就是使用训练集训练好一套参数，然后在使用验证集来验证，然后根据结果再对参数不断的进行调以达到在验证集上面也有好效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name           | Accuracy   | AUC Score \n",
      "---------------------------------------------\n",
      "Logistic Regression  | 0.8623     | 0.8743\n",
      "Random Forest        | 0.8933     | 0.9309\n",
      "XGBoost              | 0.8903     | 0.9264\n"
     ]
    }
   ],
   "source": [
    "# --- 1. 定义模型列表 ---\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=500, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=1000, learning_rate=0.05, max_depth=5, eval_metric='auc', random_state=42, n_jobs=-1)\n",
    "}\n",
    "\n",
    "# --- 2. 循环训练并评估 ---\n",
    "print(f\"{'Model Name':<20} | {'Accuracy':<10} | {'AUC Score':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # 训练\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # 预测 (验证集)\n",
    "    val_preds = model.predict(X_val_scaled)\n",
    "    val_proba = model.predict_proba(X_val_scaled)[:, 1]\n",
    "    \n",
    "    # 计算指标\n",
    "    acc = accuracy_score(y_val, val_preds)\n",
    "    auc = roc_auc_score(y_val, val_proba)\n",
    "    \n",
    "    # 存起来方便后面融合\n",
    "    results[name] = val_proba\n",
    "    \n",
    "    print(f\"{name:<20} | {acc:.4f}     | {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可以打印出来一些中间变量出来看看，这些数据长什么样子的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6721171 , 0.00171207, 0.1837626 , 0.01838813, 0.06998032],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['XGBoost'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这里是简单的对三个模型进行了简单的加权融合（当然这也有更加科学的融合方法）。\n",
    "#### 这个融合简单来说就是，每个模型对这个客户的去留都有自己的看法，然后让他们共同投票来判断这个人到底是否去留。当然因为权重的不同，所以每个模型说话的分量也是不同的。这里我们给了随机森林最重的话语权。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------------------------\n",
      ">>> 模型融合 (Ensemble) AUC: 0.9320\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# --- 简单加权融合 ---\n",
    "# XGBoost 最强，给大权重 (0.6)\n",
    "# 随机森林 次之 (0.3)\n",
    "# 逻辑回归 辅助 (0.1)\n",
    "\n",
    "ensemble_pred = (0.1 * results['Logistic Regression'] + \n",
    "                 0.6 * results['Random Forest'] + \n",
    "                 0.3 * results['XGBoost'])\n",
    "\n",
    "ensemble_auc = roc_auc_score(y_val, ensemble_pred)\n",
    "print(\"\\n---------------------------------------\")\n",
    "print(f\">>> 模型融合 (Ensemble) AUC: {ensemble_auc:.4f}\")\n",
    "print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最后我们的模型就训练好了。\n",
    "#### 现在就是在测试集上面大显身手了。之前在训练过程中测试集是完全没有出现的（在特征工程中出现过，因为需要把新特征也添加进去），所以这个模型只是学到了训练集里面的东西，现在测试集的东西对他来说都是新的，所以就可以考察这个模型到底怎样。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 融合模型预测完成！\n",
      "文件已保存为: submission_ensemble.csv\n",
      "前 5 行预览：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15000</td>\n",
       "      <td>0.044435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15001</td>\n",
       "      <td>0.245009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15002</td>\n",
       "      <td>0.010025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15003</td>\n",
       "      <td>0.816130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15004</td>\n",
       "      <td>0.008461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    Exited\n",
       "0  15000  0.044435\n",
       "1  15001  0.245009\n",
       "2  15002  0.010025\n",
       "3  15003  0.816130\n",
       "4  15004  0.008461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- 1. 让三个模型分别预测测试集 (Test Set) ---\n",
    "# 注意：这里用的是 X_test_scaled (测试集数据)，不是 X_val_scaled\n",
    "test_probs_lr  = models['Logistic Regression'].predict_proba(X_test_scaled)[:, 1]\n",
    "test_probs_rf  = models['Random Forest'].predict_proba(X_test_scaled)[:, 1]\n",
    "test_probs_xgb = models['XGBoost'].predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# --- 2. 按照同样的权重进行融合 ---\n",
    "# 权重必须和验证集上一样：XGBoost(0.6) + RF(0.3) + LR(0.1)\n",
    "ensemble_test_preds = (0.1 * test_probs_lr + \n",
    "                       0.6 * test_probs_rf + \n",
    "                       0.3 * test_probs_xgb)\n",
    "\n",
    "# --- 3. 生成最终提交文件 ---\n",
    "submission_ensemble = pd.DataFrame({\n",
    "    'id': test_df['id'],\n",
    "    'Exited': ensemble_test_preds\n",
    "})\n",
    "\n",
    "# 保存为新文件，方便和单模型对比\n",
    "submission_ensemble.to_csv('submission_ensemble.csv', index=False)\n",
    "\n",
    "print(\"✅ 融合模型预测完成！\")\n",
    "print(\"文件已保存为: submission_ensemble.csv\")\n",
    "print(\"前 5 行预览：\")\n",
    "display(submission_ensemble.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
